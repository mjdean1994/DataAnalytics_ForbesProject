{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Recall Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Code\n",
    "\n",
    "This is the code required to load the datasets we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "\n",
    "data_path = 'data'\n",
    "fields_path = 'fields'\n",
    "\n",
    "# Written by: David\n",
    "# Read and parse a file containing column names for a dataset.\n",
    "# Returns a list of strings (the column names).\n",
    "def load_column_names(columns_file_name):\n",
    "    file = open(columns_file_name)\n",
    "    column_names = []\n",
    "    readingFields = False\n",
    "    for line in file:\n",
    "        if readingFields:\n",
    "            if re.match('^[0-9]', line):\n",
    "                split_line = line.split()\n",
    "                column_names.append(split_line[1])\n",
    "        elif line.startswith('Field#'):\n",
    "            readingFields = True\n",
    "    file.close()\n",
    "    return column_names\n",
    "#}\n",
    "\n",
    "# Written by: David\n",
    "# Load a dataest by its abbreviated names (ex: RCL).\n",
    "def load_data_file(name, encoding):\n",
    "    \n",
    "    # Read the column names from a separate file.\n",
    "    fields_file_name = fields_path + '/' + name + '.txt';\n",
    "    names = load_column_names(fields_file_name)\n",
    "    \n",
    "    # Read the data from a CSV file.\n",
    "    data_file_name = 'FLAT_' + name + '.txt';\n",
    "    df = pd.read_csv(data_path + '/' + data_file_name,\n",
    "                     delimiter='\\t', header=None, encoding=encoding, names=names)\n",
    "    \n",
    "    return df\n",
    "#}\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Complaints dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the complaints dataset.\n",
    "# Only use a subset of the data (because there is a lot of it)\n",
    "cmpl_train_df = load_data_file('CMPL', encoding='iso-8859-1').tail(50000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and clean the Complaints dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: David\n",
    "# Create list of the columns we will use.\n",
    "key_cols = ['MAKETXT', 'MODELTXT', 'YEARTXT','COMPDESC']\n",
    "cat_cols = ['DRIVE_TRAIN', 'FUEL_SYS', 'FUEL_TYPE', 'TRANS_TYPE']\n",
    "bool_cols = ['CRASH', 'FIRE', 'POLICE_RPT_YN', 'ORIG_OWNER_YN', 'ANTI_BRAKES_YN', 'CRUISE_CONT_YN', 'MEDICAL_ATTN', 'VEHICLES_TOWED_YN']\n",
    "numer_cols = bool_cols + ['INJURED', 'DEATHS', 'MILES', 'OCCURENCES', 'NUM_CYLS', 'VEH_SPEED']\n",
    "all_cols = key_cols + numer_cols + cat_cols\n",
    "\n",
    "# Written by: David\n",
    "# Filter out rows with invalid make, model, or year.\n",
    "# Also filter out any non-vehicles.\n",
    "clean_train_df = cmpl_train_df[(cmpl_train_df['MAKETXT'] != 'UNKNOWN') &\n",
    "                   (cmpl_train_df['MODELTXT'] != 'UNKNOWN') &\n",
    "                   (cmpl_train_df['YEARTXT'] > 1900) &\n",
    "                   (cmpl_train_df['YEARTXT'] < 2020) &\n",
    "                   (cmpl_train_df['PROD_TYPE'] == 'V')][all_cols + ['CMPLID']].copy()\n",
    "\n",
    "# Written by: Christian\n",
    "# shoulda bought more ram\n",
    "del cmpl_train_df\n",
    "\n",
    "# Written by: David\n",
    "# Convert certain columns to a numerical data type.\n",
    "clean_train_df['NUM_CYLS'] = pd.to_numeric(clean_train_df['NUM_CYLS'], errors='coerce')\n",
    "\n",
    "# Written by: David\n",
    "# Replace particular \"bogus\" values with NaN, which get filled later.\n",
    "clean_train_df['INJURED'] = clean_train_df['INJURED'].replace(99, np.nan).fillna(0)\n",
    "clean_train_df['DEATHS'] = clean_train_df['DEATHS'].replace(99, np.nan).fillna(0)\n",
    "\n",
    "# Written by: David\n",
    "# Clamp the values for specific numerical columns.\n",
    "clean_train_df['NUM_CYLS'] = clean_train_df['NUM_CYLS'].clip(4, 8)\n",
    "clean_train_df['MILES'] = clean_train_df['MILES'].clip(0, 300000)\n",
    "clean_train_df['OCCURENCES'] = clean_train_df['OCCURENCES'].clip(1, 10)\n",
    "clean_train_df['VEH_SPEED'] = clean_train_df['VEH_SPEED'].clip(0, 100)\n",
    "\n",
    "# Written by: Christian\n",
    "# Clean values in component descriptions\n",
    "# Custom split function to pass to apply\n",
    "def split(comp):\n",
    "    if type(comp) != str:\n",
    "        return ''\n",
    "    return comp.split(':')[0]\n",
    "\n",
    "# Written by: Christian\n",
    "# Generalize the names of each component\n",
    "clean_train_df['COMPDESC'] = clean_train_df['COMPDESC'].apply(split)\n",
    "\n",
    "# Written by: Christian\n",
    "# Fix differences between component names in complaints and recalls\n",
    "clean_train_df['COMPDESC'] = clean_train_df['COMPDESC'].replace('FUEL/PROPULSION SYSTEM','FUEL SYSTEM').replace('AIR BAG','AIR BAGS')\n",
    "clean_train_df['COMPDESC'] = clean_train_df['COMPDESC'].replace('OTHER','').replace('UNKNOWN OR OTHER','')\n",
    "\n",
    "# Written by: David\n",
    "# Replace 'Y' and 'N' with 1 and 0 for boolean columns.\n",
    "# Also convert them to numeric so we can average them.\n",
    "# This will allow us to get a percentage of 'yes' for each vehicle type.\n",
    "for column in bool_cols:\n",
    "    clean_train_df[column] = clean_train_df[column].replace('Y', 1).replace('N', 0)\n",
    "    clean_train_df[column] = pd.to_numeric(clean_train_df[column])\n",
    "\n",
    "# Print out part of the resulting semi-clean data set\n",
    "clean_train_df[all_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group complaints by make/model/year and perform aggregate functions on the column values\n",
    "\n",
    "Warning: this step takes a few minutes to perform all the aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Written by: David\n",
    "# Aggregate function which Returns the mode of a series.\n",
    "# If there is no valid mode, but there are any amount of\n",
    "# non-null values, then the first non-null value is returned.\n",
    "# Otherwise, if all values are NaN, then NaN is returned\n",
    "def aggMode(x):\n",
    "    column_mode = x.mode()\n",
    "    \n",
    "    # If there is a valid mode, return it\n",
    "    if column_mode.count() > 0:\n",
    "        return column_mode[0]\n",
    "   \n",
    "    # if there are any non-null values, return one of them\n",
    "    first_valid = x.first_valid_index()\n",
    "    if first_valid != None:\n",
    "        return x[first_valid]\n",
    "    \n",
    "    return np.nan\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: David\n",
    "# Group the dataset by the key columns (make/model/year/component)\n",
    "grouped = clean_train_df.groupby(key_cols)\n",
    "\n",
    "# Written by: David\n",
    "# Perform aggregate functions on the columns for each vehicle type.\n",
    "# Aggregate with the mode for categorical columns\n",
    "# Aggregate with the mean for numerical columns\n",
    "grouped_df = pd.DataFrame()\n",
    "for col in cat_cols:\n",
    "    grouped_df[col] = grouped[col].agg(aggMode)\n",
    "for col in numer_cols:\n",
    "    grouped_df[col] = grouped[col].mean()\n",
    "\n",
    "# Written by: David\n",
    "# Add in a column for the number of complaints for each vehicle-component.\n",
    "grouped_df['COMPLAINTS'] = grouped.size()\n",
    "numer_cols.append('COMPLAINTS');\n",
    "all_cols.append('COMPLAINTS');\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace missing values with the mean or mode for that column over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: David\n",
    "\n",
    "# Replace NaN with mode for categorical columns\n",
    "for col in cat_cols:\n",
    "    grouped_df[col] = grouped_df[col].fillna(grouped_df[col].mode()[0])\n",
    "\n",
    "# Replace NaN with mean for numerical columns\n",
    "for col in numer_cols:\n",
    "    grouped_df[col] = grouped_df[col].fillna(grouped_df[col].mean())\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print out the grouped dataset.\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check which vehicle types exist in the Recalls dataset\n",
    "\n",
    "Warning: This is the longest step and it will take several minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the recall dataset\n",
    "rcl_df = load_data_file('RCL', encoding='latin1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: Christian\n",
    "# Rename the component field in recalls so it matches complaints\n",
    "recalled_set = rcl_df.rename(columns = {'COMPNAME':'COMPDESC'})\n",
    "\n",
    "# Written by: David\n",
    "# Create the set of vehicle types from the recalled dataset.\n",
    "# Filter out rows with invalid make, model, or year.\n",
    "# Also filter out any non-vehicles.\n",
    "recalled_set = recalled_set[(rcl_df['MAKETXT'] != 'UNKNOWN') &\n",
    "                      (rcl_df['MODELTXT'] != 'UNKNOWN') &\n",
    "                      (rcl_df['YEARTXT'] > 1900) &\n",
    "                      (rcl_df['YEARTXT'] < 2020) &\n",
    "                      (rcl_df['RCLTYPECD'] == 'V')][key_cols].copy()\n",
    "\n",
    "# Written by: Christian\n",
    "# Generalize the names of each component\n",
    "recalled_set['COMPDESC'] = recalled_set['COMPDESC'].apply(split)\n",
    "\n",
    "# Written by: David\n",
    "# Make the recalled set only have unique vehicle types,\n",
    "# mostly for efficiency in the next step.\n",
    "recalled_set = recalled_set[key_cols].groupby(key_cols).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Written by: Matt\n",
    "# Create the column in the complaints set which says\n",
    "# whether a vehicle type is in the recalled set.\n",
    "grouped_df['RECALLED'] = False\n",
    "for index, row in grouped_df.iterrows():\n",
    "    row['RECALLED'] = index in recalled_set.index\n",
    "    grouped_df.loc[index] = row\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Decision Forest Prediction\n",
    "\n",
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: Matt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to grab 'n' number of random samples from a dataframe 'x'\n",
    "import random\n",
    "def some(x, n):\n",
    "    return x.ix[random.sample(set(x.index), n)]\n",
    "\n",
    "# Split the data frame by the recalled values.\n",
    "recalledSamples = grouped_df[grouped_df['RECALLED'] == True];\n",
    "nonRecalledSamples = grouped_df[grouped_df['RECALLED'] == False];\n",
    "\n",
    "# Grab an equal number of random samples from each set.\n",
    "numSamples = min(recalledSamples.shape[0], nonRecalledSamples.shape[0])\n",
    "fullData = some(recalledSamples, numSamples)\n",
    "fullData = fullData.append(some(nonRecalledSamples, numSamples))\n",
    "\n",
    "print('Gathered', numSamples, 'recalled components and',\n",
    "      numSamples, 'non-recalled components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: David\n",
    "# Drop columns that have missing values. Our previous\n",
    "# steps would have filled all missing values UNLESS\n",
    "# the column is entirely filled with null. Therefore,\n",
    "# just drop columns that are null, they don't tell us anything.\n",
    "for col in cat_cols + numer_cols:\n",
    "    if fullData[col].isnull().any():\n",
    "        print('Dropping column ', col)\n",
    "        fullData[col].drop(col, axis=1)\n",
    "\n",
    "# Written by: Matt\n",
    "# Create label encoders for categorical features\n",
    "for var in cat_cols:\n",
    "    number = LabelEncoder()\n",
    "    fullData[var] = number.fit_transform(fullData[var].astype('str'))\n",
    "\n",
    "# Written by: Matt\n",
    "# Target variable is also a categorical so convert it\n",
    "fullData['RECALLED'] = number.fit_transform(fullData['RECALLED'].astype('str'))\n",
    "\n",
    "# Written by: Matt\n",
    "# Split train dataset into train and validation sub-sets\n",
    "fullData['is_train'] = np.random.uniform(0, 1, len(fullData)) <= .75\n",
    "Train, Validate = fullData[fullData['is_train']==True], fullData[fullData['is_train']==False]\n",
    "\n",
    "print('Training set size =', Train.shape[0])\n",
    "print('Validation set size =', Validate.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: Matt\n",
    "# Get a list of the defining features.\n",
    "features = list(set(list(fullData.columns)) - set(['RECALLED']))\n",
    "\n",
    "# Written by: Matt\n",
    "x_train = Train[list(features)].values\n",
    "y_train = Train['RECALLED'].values\n",
    "x_validate = Validate[list(features)].values\n",
    "y_validate = Validate['RECALLED'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plot the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: Matt\n",
    "# Create the random forest classifier\n",
    "random.seed(100)\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Written by: Matt\n",
    "# Predict the probablies of recalls for the validation set.\n",
    "status = rf.predict_proba(x_validate)\n",
    "\n",
    "# Written by: Matt\n",
    "# Calculate the ROC curve and Area under the curve.\n",
    "fpr, tpr, _ = roc_curve(y_validate, status[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Area under ROC curve =', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: Matt\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: David\n",
    "\n",
    "# Get a list of the actual recalled states.\n",
    "y_true = y_validate\n",
    "\n",
    "# Get a list of the predicted recalled states.\n",
    "# The status array holds probabilities whether something is recalled\n",
    "y_pred = np.array([(item[1] >= 0.5) for item in status]).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('confusion matrix:')\n",
    "print(cnf_matrix)\n",
    "\n",
    "# Now print out what it MEANS:\n",
    "print()\n",
    "print(cnf_matrix[0][0], ' non-recalled cars were predicted to be not recalled')\n",
    "print(cnf_matrix[0][1], ' non-recalled cars were predicted to be recalled')\n",
    "print(cnf_matrix[1][0], ' recalled cars were predicted to be not recalled')\n",
    "print(cnf_matrix[1][1], ' recalled cars were predicted to be recalled')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Accuracy & Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written by: David\n",
    "\n",
    "print('accuracy =', accuracy_score(y_true, y_pred))\n",
    "print('Mean squared error =', mean_squared_error(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
